# Lab 04: Text Representation

In this lab, I explored how raw text is converted into numerical form so that it can be used in machine learning models. This process is essential for Natural Language Processing (NLP) tasks.

## Topics Covered
- Tokenization
- Stopword removal
- Bag-of-Words (BoW)
- TF-IDF (Term Frequencyâ€“Inverse Document Frequency)
- Vectorization techniques

## Key Takeaways
- Text must be cleaned and transformed into vectors for machines to understand it.
- BoW and TF-IDF are foundational methods for representing text in NLP.
- Choosing the right representation can impact model accuracy and performance.

## Tools Used
- NLTK
- Scikit-learn
- Python
- Jupyter Notebook
